#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Stereo YOLOv8n-Seg (first 10 frames merged) + MediaPipe-on-Left â†’ Live overlay (mm)
+ Laser-origin yaw/pitch per hold (LEFT-camera-based)
+ âœ… DualServoController ì—°ë™: ì´ˆê¸° ê°ë„ëŠ” CLIë¡œ 1íšŒë§Œ ì„¤ì •, ì´í›„ ì†ê°€ë½ì´ ìž¡ìœ¼ë©´ ë‹¤ìŒ í™€ë“œë¡œ ìžë™ ì´ë™

- ì‹œìž‘ ì‹œ ì²« 10í”„ë ˆìž„ì—ì„œ YOLO ì„¸ê·¸ â†’ í”„ë ˆìž„ ê°„ ì¤‘ë³µ ë³‘í•© â†’ yí–‰/xì •ë ¬ë¡œ hold_index ë¶€ì—¬
- ì¢Œ/ìš° ê³µí†µ hold_index ìŒë§Œ ì‚¼ê°ì¸¡ëŸ‰ â†’ X(mm), yaw/pitch(ë ˆì´ì € ì›ì =LEFTê¸°ì¤€) ê³„ì‚°
- ì‹œìž‘ ì‹œ: (ì˜µì…˜) --center ë˜ëŠ” --pitch/--yaw ë¡œ 1íšŒë§Œ ìˆ˜ë™ ì´ˆê¸°ì„¸íŒ…
- ë¼ì´ë¸Œ: MediaPipeë¡œ 'í˜„ìž¬ íƒ€ê¹ƒ í™€ë“œ'ì— ì†ê°€ë½ì´ TOUCH_THRESHOLD í”„ë ˆìž„ ì´ìƒ ë“¤ì–´ì˜¤ë©´ ë‹¤ìŒ í™€ë“œë¡œ ìžë™ ì´ë™
- ì €ìž¥: grip_records.csv ë§Œ ì €ìž¥
"""

import time
import cv2
import numpy as np
from pathlib import Path
from ultralytics import YOLO
import mediapipe as mp
import csv
import math
import argparse

# ======== (NEW) DualServoController ê°€ì ¸ì˜¤ê¸° ========
# - servo_control.pyì˜ ì§ë ¬ ëª…ë ¹ í˜•ì‹ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
# - ì—†ìœ¼ë©´ ë”ë¯¸ ì»¨íŠ¸ë¡¤ëŸ¬ë¡œ ì•ˆì „ ë™ìž‘
try:
    from servo_control import DualServoController  # S pitch yaw / P / Y / C / R / Z
    HAS_SERVO = True
except Exception:
    HAS_SERVO = False
    class DualServoController:
        def __init__(self, *a, **k): print("[Servo] (stub) controller unavailable")
        def set_angles(self, pitch=None, yaw=None): print(f"[Servo] (stub) set_angles: P={pitch}, Y={yaw}")
        def center(self): print("[Servo] (stub) center")
        def query(self): print("[Servo] (stub) query"); return ""
        def laser_on(self): print("[Servo] (stub) laser_on")
        def laser_off(self): print("[Servo] (stub) laser_off")
        def close(self): pass

# ========= ì‚¬ìš©ìž ì„¤ì • =========
NPZ_PATH       = r"C:\Users\user\Documents\ìº¡ìŠ¤í„´ ë””ìžì¸\triangulation\calib_out\old_camera_same\stereo\stereo_params_scaled.npz"
MODEL_PATH     = r"C:\Users\user\Documents\ìº¡ìŠ¤í„´ ë””ìžì¸\triangulation\best_6.pt"

CAM1_INDEX     = 1   # ë¬¼ë¦¬ ì¹´ë©”ë¼ ì¸ë±ìŠ¤(ì™¼ìª½)
CAM2_INDEX     = 2   # ë¬¼ë¦¬ ì¹´ë©”ë¼ ì¸ë±ìŠ¤(ì˜¤ë¥¸ìª½)

# ìž…ë ¥(ìº¡ì²˜) ì¢Œ/ìš°ê°€ ë³´ì •(P1/P2)ê³¼ ë’¤ì§‘í˜”ë‹¤ë©´ Trueë¡œ (ì •ì„ í•´ê²°)
SWAP_INPUT     = False

# í™”ë©´(UI)ë§Œ ì¢Œ/ìš° ë°”ê¿”ì„œ í‘œì‹œí• ì§€ (ì˜¤ë²„ë ˆì´/í…ìŠ¤íŠ¸ ì˜¤í”„ì…‹ ìžë™ ì •í•©)
SWAP_DISPLAY   = False

WINDOW_NAME    = "Rectified L | R  (10f merged; MP Left; Servo Auto-Advance)"
SHOW_GRID      = False
THRESH_MASK    = 0.7
ROW_TOL_Y      = 30
SELECTED_COLOR = None    # ì˜ˆ: 'orange' (Noneì´ë©´ ì½˜ì†” ìž…ë ¥/ì—”í„°=ì „ì²´)

SAVE_VIDEO     = False
OUT_FPS        = 30
OUT_PATH       = "stereo_overlay.mp4"

CSV_GRIPS_PATH  = "grip_records.csv"
TOUCH_THRESHOLD = 10  # ì—°ì† í”„ë ˆìž„
# =================================

# ---- ë ˆì´ì € ì›ì (=ì¡°ì¤€ ê¸°ì¤€ì ) ì˜¤í”„ì…‹ (LEFT ì¹´ë©”ë¼ ì›ì  ê¸°ì¤€, cm) ----
LASER_OFFSET_CM_LEFT = 1.85   # 'ì™¼ìª½'ì€ x ìŒ(-)
LASER_OFFSET_CM_UP   = 8.0    # 'ìœ„ìª½'ì€ y ìŒ(-)
LASER_OFFSET_CM_FWD  = -3.3   # ì „ë°© +, ë’¤ìª½ - â†’ ë’¤ 3.3cmì´ë¯€ë¡œ -3.3
Y_UP_IS_NEGATIVE = True       # ìœ„ê°€ -y

# ê°„ë‹¨ ì˜¤í”„ì…‹ ë³´ì •(í˜„ìž¥ íŠœë‹)
YAW_OFFSET_DEG   = 0.0
PITCH_OFFSET_DEG = 0.0

# (ì„ íƒ) 2x2 ì„ í˜• ë³´ì • ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€
USE_LINEAR_CAL = False
A11, A12, B1 = 1.0, 0.0, 0.0    # yaw_cmd = A11*yaw_est + A12*pitch_est + B1
A21, A22, B2 = 0.0, 1.0, 0.0    # pitch_cmd = A21*yaw_est + A22*pitch_est + B2

# (ì„ íƒ) í”„ë¦¬ë·° ìµœëŒ€ í­
PREVIEW_MAX_W = None  # ì˜ˆ: 1280

# ==== ì´ˆê¸° YOLO í”„ë ˆìž„ ìˆ˜ & ë³‘í•© ê¸°ì¤€ ====
INIT_DET_FRAMES   = 10
CENTER_MERGE_PX   = 18
# ==============================

# YOLO í´ëž˜ìŠ¤ ì»¬ëŸ¬ (BGR)
COLOR_MAP = {
    'Hold_Red':(0,0,255),'Hold_Orange':(0,165,255),'Hold_Yellow':(0,255,255),
    'Hold_Green':(0,255,0),'Hold_Blue':(255,0,0),'Hold_Purple':(204,50,153),
    'Hold_Pink':(203,192,255),'Hold_Lime':(50,255,128),'Hold_Sky':(255,255,0),
    'Hold_White':(255,255,255),'Hold_Black':(30,30,30),'Hold_Gray':(150,150,150),
}
ALL_COLORS = {
    'red':'Hold_Red','orange':'Hold_Orange','yellow':'Hold_Yellow','green':'Hold_Green',
    'blue':'Hold_Blue','purple':'Hold_Purple','pink':'Hold_Pink','white':'Hold_White',
    'black':'Hold_Black','gray':'Hold_Gray','lime':'Hold_Lime','sky':'Hold_Sky',
}

# ---------- ìœ í‹¸ ----------
def ask_color_and_map_to_class(all_colors_dict):
    print("ðŸŽ¨ ì„ íƒ ê°€ëŠ¥í•œ ìƒ‰ìƒ:", ", ".join(all_colors_dict.keys()))
    s = input("âœ… ì›í•˜ëŠ” í™€ë“œ ìƒ‰ìƒ ìž…ë ¥(ì—”í„°=ì „ì²´): ").strip().lower()
    if not s:
        print("â†’ ì „ì²´ í´ëž˜ìŠ¤ ì‚¬ìš©"); return None
    mapped = all_colors_dict.get(s)
    if mapped is None:
        print(f"âš ï¸ '{s}' ëŠ” ìœ íš¨í•˜ì§€ ì•Šì€ ìƒ‰ìƒìž…ë‹ˆë‹¤. ì „ì²´ í´ëž˜ìŠ¤ ì‚¬ìš©")
        return None
    print(f"ðŸŽ¯ ì„ íƒëœ í´ëž˜ìŠ¤: {mapped}")
    return mapped

def load_stereo(npz_path):
    S = np.load(npz_path, allow_pickle=True)
    K1, D1 = S["K1"], S["D1"]; K2, D2 = S["K2"], S["D2"]
    R1, R2 = S["R1"], S["R2"]; P1, P2 = S["P1"], S["P2"]
    W, H   = [int(x) for x in S["image_size"]]
    map1x, map1y = cv2.initUndistortRectifyMap(K1, D1, R1, P1, (W, H), cv2.CV_32FC1)
    map2x, map2y = cv2.initUndistortRectifyMap(K2, D2, R2, P2, (W, H), cv2.CV_32FC1)
    Tx = -P2[0,3] / P2[0,0]
    B  = float(abs(Tx))
    M  = np.array([0.5*Tx, 0.0, 0.0], dtype=np.float64)  # ì¤‘ì (ì •ë³´ìš©)
    return (map1x, map1y, map2x, map2y, P1, P2, (W, H), B, M)

def open_cams(idx1, idx2, size):
    W, H = size
    cap1 = cv2.VideoCapture(idx1, cv2.CAP_DSHOW)
    cap2 = cv2.VideoCapture(idx2, cv2.CAP_DSHOW)
    cap1.set(cv2.CAP_PROP_FRAME_WIDTH,  W); cap1.set(cv2.CAP_PROP_FRAME_HEIGHT, H)
    cap2.set(cv2.CAP_PROP_FRAME_WIDTH,  W); cap2.set(cv2.CAP_PROP_FRAME_HEIGHT, H)
    if not cap1.isOpened() or not cap2.isOpened():
        raise SystemExit("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¸ë±ìŠ¤/ì—°ê²° í™•ì¸.")
    return cap1, cap2

def rectify(frame, mx, my, size):
    W, H = size
    if (frame.shape[1], frame.shape[0]) != (W, H):
        frame = cv2.resize(frame, (W, H))
    return cv2.remap(frame, mx, my, cv2.INTER_LINEAR)

def extract_holds_with_indices(frame_bgr, model, selected_class_name=None,
                               mask_thresh=0.7, row_tol=50):
    h, w = frame_bgr.shape[:2]
    res = model(frame_bgr)[0]
    holds = []
    if res.masks is None: return []
    masks = res.masks.data; boxes = res.boxes; names = model.names
    for i in range(masks.shape[0]):
        mask = masks[i].cpu().numpy()
        mask_rs = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)
        binary = (mask_rs > mask_thresh).astype(np.uint8) * 255
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours: continue
        contour = max(contours, key=cv2.contourArea)
        cls_id = int(boxes.cls[i].item()); conf = float(boxes.conf[i].item())
        class_name = names[cls_id]
        if (selected_class_name is not None) and (class_name != selected_class_name):
            continue
        Mom = cv2.moments(contour)
        if Mom["m00"] == 0: continue
        cx = int(Mom["m10"]/Mom["m00"]); cy = int(Mom["m01"]/Mom["m00"])
        holds.append({"class_name": class_name, "color": COLOR_MAP.get(class_name,(255,255,255)),
                      "contour": contour, "center": (cx, cy), "conf": conf})
    if not holds: return []
    enriched = [{"cx": h_["center"][0], "cy": h_["center"][1], **h_} for h_ in holds]
    enriched.sort(key=lambda h: h["cy"])
    rows, cur = [], [enriched[0]]
    for h_ in enriched[1:]:
        if abs(h_["cy"] - cur[0]["cy"]) < row_tol: cur.append(h_)
        else: rows.append(cur); cur = [h_]
    rows.append(cur)
    final_sorted = []
    for row in rows:
        row.sort(key=lambda h: h["cx"])
        final_sorted.extend(row)
    for idx, h_ in enumerate(final_sorted):
        h_["hold_index"] = idx
    return final_sorted

def merge_holds_by_center(holds_lists, merge_dist_px=18):
    merged = []
    for holds in holds_lists:
        for h in holds:
            h = {k: v for k, v in h.items()}
            h.pop("hold_index", None)
            assigned = False
            for m in merged:
                dx = h["center"][0] - m["center"][0]
                dy = h["center"][1] - m["center"][1]
                if (dx*dx + dy*dy) ** 0.5 <= merge_dist_px:
                    area_h = cv2.contourArea(h["contour"])
                    area_m = cv2.contourArea(m["contour"])
                    if (area_h > area_m) or (abs(area_h - area_m) < 1e-6 and h.get("conf",0) > m.get("conf",0)):
                        m.update(h)
                    assigned = True
                    break
            if not assigned:
                merged.append(h)
    return merged

def assign_indices(holds, row_tol=50):
    if not holds:
        return []
    enriched = [{"cx": h["center"][0], "cy": h["center"][1], **h} for h in holds]
    enriched.sort(key=lambda h: h["cy"])
    rows, cur = [], [enriched[0]]
    for h_ in enriched[1:]:
        if abs(h_["cy"] - cur[0]["cy"]) < row_tol: cur.append(h_)
        else: rows.append(cur); cur = [h_]
    rows.append(cur)
    final_sorted = []
    for row in rows:
        row.sort(key=lambda h: h["cx"])
        final_sorted.extend(row)
    for idx, h_ in enumerate(final_sorted):
        h_["hold_index"] = idx
    return final_sorted

def triangulate_xy(P1, P2, ptL, ptR):
    xl = np.array(ptL, dtype=np.float64).reshape(2,1)
    xr = np.array(ptR, dtype=np.float64).reshape(2,1)
    Xh = cv2.triangulatePoints(P1, P2, xl, xr)
    X  = (Xh[:3] / Xh[3]).reshape(3)  # [X,Y,Z] (mm)
    return X

def draw_grid(img):
    h, w = img.shape[:2]; step = max(20, h//20)
    for y in range(0, h, step):
        cv2.line(img, (0,y), (w-1,y), (0,255,0), 1, cv2.LINE_AA)

def yaw_pitch_from_X(X, O, y_up_is_negative=True):
    v = X - O
    vx, vy, vz = float(v[0]), float(v[1]), float(v[2])
    yaw   = np.degrees(np.arctan2(vx, vz))
    pitch = np.degrees(np.arctan2((-vy if y_up_is_negative else vy), np.hypot(vx, vz)))
    return yaw, pitch

def angle_between(v1, v2):
    a = np.linalg.norm(v1); b = np.linalg.norm(v2)
    if a == 0 or b == 0: return 0.0
    cosang = np.clip(np.dot(v1, v2) / (a * b), -1.0, 1.0)
    return np.degrees(np.arccos(cosang))

def wrap_deg(d): return (d + 180.0) % 360.0 - 180.0

def imshow_scaled(win, img, maxw=None):
    if not maxw: cv2.imshow(win, img); return
    h, w = img.shape[:2]
    if w > maxw:
        s = maxw / w
        img = cv2.resize(img, (int(w*s), int(h*s)))
    cv2.imshow(win, img)

def xoff_for(side, W, swap):
    if side == "L":
        return (W if swap else 0)
    else:
        return (0 if swap else W)

# ---------- (NEW) Servo ë³´ì •/ì „ì†¡ ----------
def apply_calibration(yaw_est, pitch_est):
    if USE_LINEAR_CAL:
        yaw_cmd   = A11*yaw_est + A12*pitch_est + B1
        pitch_cmd = A21*yaw_est + A22*pitch_est + B2
    else:
        yaw_cmd   = yaw_est   + YAW_OFFSET_DEG
        pitch_cmd = pitch_est + PITCH_OFFSET_DEG
    return yaw_cmd, pitch_cmd

def send_servo_angles(ctl, yaw_cmd, pitch_cmd):
    # DualServoControllerëŠ” (pitch, yaw) ìˆœì„œë¡œ ì „ì†¡
    try:
        print(f"[Servo] send: yaw={yaw_cmd:.2f}Â°, pitch={pitch_cmd:.2f}Â°")
        ctl.set_angles(pitch_cmd, yaw_cmd)
    except Exception as e:
        print(f"[Servo ERROR] {e}")

# ---------- ë©”ì¸ ----------
def main():
    # ---- CLI ì¸ìž (ì´ˆê¸° 1íšŒ ì„¸íŒ…ë§Œ) ----
    ap = argparse.ArgumentParser()
    ap.add_argument("--port", default="COM4", help="ì„œë³´ ë³´ë“œ í¬íŠ¸ (ì˜ˆ: COM4)")
    ap.add_argument("--baud", type=int, default=115200)
    ap.add_argument("--center", action="store_true", help="ì‹œìž‘ ì‹œ 1íšŒ ì„¼í„° ì´ë™")
    ap.add_argument("--pitch", type=float, help="ì‹œìž‘ ì‹œ 1íšŒ ìˆ˜ë™ pitch ê°ë„")
    ap.add_argument("--yaw",   type=float, help="ì‹œìž‘ ì‹œ 1íšŒ ìˆ˜ë™ yaw ê°ë„")
    ap.add_argument("--laser_on",  action="store_true", help="ì‹œìž‘ ì‹œ ë ˆì´ì € ON")
    ap.add_argument("--laser_off", action="store_true", help="ì‹œìž‘ ì‹œ ë ˆì´ì € OFF")
    ap.add_argument("--no_auto_advance", action="store_true", help="ì† ì¸ì‹ ìžë™ ë„˜ê¹€ ë¹„í™œì„±í™”")
    args = ap.parse_args()

    # ê²½ë¡œ ê²€ì‚¬
    for p in (NPZ_PATH, MODEL_PATH):
        if not Path(p).exists():
            raise FileNotFoundError(f"íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {p}")

    # ì¤€ë¹„
    map1x, map1y, map2x, map2y, P1, P2, size, B, M = load_stereo(NPZ_PATH)
    W, H = size
    print(f"[Info] image_size={(W,H)}, baseline~{B:.2f} mm")

    # ë ˆì´ì € ì›ì  O (LEFT ì¹´ë©”ë¼ ê¸°ì¤€ ì˜¤í”„ì…‹)
    L = np.array([0.0, 0.0, 0.0], dtype=np.float64)
    dx = -LASER_OFFSET_CM_LEFT * 10.0
    dy = (-1.0 if Y_UP_IS_NEGATIVE else 1.0) * LASER_OFFSET_CM_UP * 10.0
    dz = LASER_OFFSET_CM_FWD * 10.0
    O  = L + np.array([dx, dy, dz], dtype=np.float64)
    print(f"[Laser] Origin O (mm, LEFT-based) = {O}")

    # ìƒ‰ìƒ í•„í„° ì„ íƒ
    if SELECTED_COLOR is not None:
        sc = SELECTED_COLOR.strip().lower()
        selected_class_name = ALL_COLORS.get(sc)
        if selected_class_name is None:
            print(f"[Filter] SELECTED_COLOR='{SELECTED_COLOR}' ì¸ì‹ ì‹¤íŒ¨. ì½˜ì†”ì—ì„œ ì„ íƒí•©ë‹ˆë‹¤.")
            selected_class_name = ask_color_and_map_to_class(ALL_COLORS)
        else:
            print(f"[Filter] ì„ íƒ í´ëž˜ìŠ¤(ìƒìˆ˜): {selected_class_name}")
    else:
        selected_class_name = ask_color_and_map_to_class(ALL_COLORS)

    # ì¹´ë©”ë¼ & ëª¨ë¸
    capL_idx, capR_idx = CAM1_INDEX, CAM2_INDEX
    if SWAP_INPUT:
        capL_idx, capR_idx = capR_idx, capL_idx
    cap1, cap2 = open_cams(capL_idx, capR_idx, size)
    model = YOLO(str(MODEL_PATH))

    # ====== ì´ˆê¸° 10í”„ë ˆìž„ ìˆ˜ì§‘ & YOLO â†’ ë³‘í•© ======
    print(f"[Init] First {INIT_DET_FRAMES} frames: YOLO seg & merge ...")
    L_sets, R_sets = [], []
    for _ in range(2):  # ì›Œë°ì—…
        cap1.read(); cap2.read()
    for k in range(INIT_DET_FRAMES):
        ok1, f1 = cap1.read(); ok2, f2 = cap2.read()
        if not (ok1 and ok2):
            cap1.release(); cap2.release()
            raise SystemExit("ì´ˆê¸° í”„ë ˆìž„ ìº¡ì²˜ ì‹¤íŒ¨")
        Lr_k = rectify(f1, map1x, map1y, size)
        Rr_k = rectify(f2, map2x, map2y, size)
        holdsL_k = extract_holds_with_indices(Lr_k, model, selected_class_name, THRESH_MASK, ROW_TOL_Y)
        holdsR_k = extract_holds_with_indices(Rr_k, model, selected_class_name, THRESH_MASK, ROW_TOL_Y)
        L_sets.append(holdsL_k); R_sets.append(holdsR_k)
        print(f"  - frame {k+1}/{INIT_DET_FRAMES}: L={len(holdsL_k)}  R={len(holdsR_k)}")

    # ë³‘í•© í›„ ì¸ë±ìŠ¤ ìž¬ë¶€ì—¬
    holdsL = assign_indices(merge_holds_by_center(L_sets, CENTER_MERGE_PX), ROW_TOL_Y)
    holdsR = assign_indices(merge_holds_by_center(R_sets, CENTER_MERGE_PX), ROW_TOL_Y)
    if not holdsL or not holdsR:
        cap1.release(); cap2.release()
        print("[Warn] í•œìª½ ë˜ëŠ” ì–‘ìª½ì—ì„œ í™€ë“œê°€ ê²€ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # ì¢Œ/ìš° ê³µí†µ hold_index
    idxL = {h["hold_index"]: h for h in holdsL}
    idxR = {h["hold_index"]: h for h in holdsR}
    common_ids = sorted(set(idxL.keys()) & set(idxR.keys()))
    if not common_ids:
        print("[Warn] ì¢Œ/ìš° ê³µí†µ hold_indexê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print(f"[Info] ë§¤ì¹­ëœ í™€ë“œ ìŒ ìˆ˜: {len(common_ids)}")

    # ë§¤ì¹­ ê²°ê³¼(3D/ê°ë„) â€” LEFT ì›ì  ê¸°ë°˜
    matched_results = []
    for hid in common_ids:
        Lh = idxL[hid]; Rh = idxR[hid]
        X = triangulate_xy(P1, P2, Lh["center"], Rh["center"])
        yaw_deg, pitch_deg = yaw_pitch_from_X(X, O, Y_UP_IS_NEGATIVE)
        matched_results.append({
            "hid": hid, "color": Lh["color"], "X": X,
            "yaw_deg": yaw_deg, "pitch_deg": pitch_deg,
        })
    by_id = {mr["hid"]: mr for mr in matched_results}
    sorted_ids = sorted(by_id.keys())

    # ===== (NEW) ì„œë³´ ì»¨íŠ¸ë¡¤ëŸ¬ ì´ˆê¸°í™” & 1íšŒ ì´ˆê¸°ì„¸íŒ… =====
    ctl = DualServoController(args.port, args.baud) if HAS_SERVO else DualServoController()
    try:
        if args.center:
            print(ctl.center())
        if args.laser_on:
            ctl.laser_on()
        if args.laser_off:
            ctl.laser_off()
        if (args.pitch is not None) or (args.yaw is not None):
            # âœ… ì‚¬ìš©ìžê°€ CLIë¡œ ì¤€ ì´ˆê¸° ê°ë„ 1íšŒë§Œ ì ìš©
            print(ctl.set_angles(args.pitch, args.yaw))
        else:
            # ì‚¬ìš©ìžê°€ ì´ˆê¸°ê°ë„ ë¯¸ì§€ì •ì´ë©´, ì²« íƒ€ê¹ƒ(ìµœì†Œ ID) ê°ë„ë¡œ 1íšŒ ì´ë™
            if sorted_ids:
                first = by_id[sorted_ids[0]]
                yaw_cmd, pitch_cmd = apply_calibration(first["yaw_deg"], first["pitch_deg"])
                send_servo_angles(ctl, yaw_cmd, pitch_cmd)
    except Exception as e:
        print(f"[Servo Init ERROR] {e}")

    # ==== MediaPipe Pose (ì™¼ìª½ ì¹´ë©”ë¼ ì „ìš©) ====
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)
    important_landmarks = {"left_index": 15, "right_index": 16}
    hand_parts = set(important_landmarks.keys())

    # í„°ì¹˜ ê¸°ë¡ ìƒíƒœ
    grip_records = []         # [part, hold_id, cx, cy]
    already_grabbed = {}      # key=(name, hold_index) â†’ True
    touch_counters = {}       # key=(name, hold_index) â†’ ì—°ì† ì¹´ìš´íŠ¸

    # (NEW) ìžë™ ì§„í–‰ ìƒíƒœ
    auto_advance_enabled = (not args.no_auto_advance)
    current_target_id = sorted_ids[0] if sorted_ids else None
    last_advanced_time = 0.0
    ADV_COOLDOWN = 0.5  # ì´ˆê³¼ íŠ¸ë¦¬ê±° ë°©ì§€(ì´ˆ)

    # ë¹„ë””ì˜¤ ì €ìž¥
    out = None
    if SAVE_VIDEO:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(OUT_PATH, fourcc, OUT_FPS, (W*2, H))

    # ë¼ì´ë¸Œ ë£¨í”„
    cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)
    t_prev = time.time(); frame_idx = 0

    while True:
        ok1, f1 = cap1.read(); ok2, f2 = cap2.read()
        if not (ok1 and ok2):
            print("[Warn] í”„ë ˆìž„ ì½ê¸° ì‹¤íŒ¨"); break

        Lr = rectify(f1, map1x, map1y, size)
        Rr = rectify(f2, map2x, map2y, size)

        # í™”ë©´ ê²°í•©(í‘œì‹œë§Œ ìŠ¤ì™‘ ì˜µì…˜)
        vis = np.hstack([Rr, Lr]) if SWAP_DISPLAY else np.hstack([Lr, Rr])
        if SHOW_GRID:
            draw_grid(vis[:, :W]); draw_grid(vis[:, W:])

        # ì´ˆê¸° 10í”„ë ˆìž„ ë³‘í•© ê²°ê³¼ë¥¼ ë¼ë²¨ë¡œ ê·¸ë¦¼ (ì¢Œ/ìš° ë‘˜ ë‹¤)
        for side, holds in (("L", holdsL), ("R", holdsR)):
            xoff = xoff_for(side, W, SWAP_DISPLAY)
            for h in holds:
                cnt_shifted = h["contour"] + np.array([[[xoff, 0]]], dtype=h["contour"].dtype)
                cv2.drawContours(vis, [cnt_shifted], -1, h["color"], 2)
                cx, cy = h["center"]
                cv2.circle(vis, (cx+xoff, cy), 4, (255,255,255), -1)
                tag = f"ID:{h['hold_index']}"
                if (current_target_id is not None) and (h["hold_index"] == current_target_id):
                    tag = "[TARGET] " + tag
                cv2.putText(vis, tag, (cx+xoff-10, cy+26),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 3, cv2.LINE_AA)
                cv2.putText(vis, tag, (cx+xoff-10, cy+26),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, h["color"], 2, cv2.LINE_AA)

        # íƒ€ê¹ƒ ê°ë„ í…ìŠ¤íŠ¸
        y0 = 26
        if current_target_id in by_id:
            mr = by_id[current_target_id]
            txt = (f"TARGET ID{mr['hid']}  "
                   f"yaw={mr['yaw_deg']:.1f}Â°, pitch={mr['pitch_deg']:.1f}Â°")
            cv2.putText(vis, txt, (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 3, cv2.LINE_AA)
            cv2.putText(vis, txt, (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 1, cv2.LINE_AA)
            y0 += 26

        # MediaPipe Pose: ì™¼ìª½ë§Œ
        image_rgb = cv2.cvtColor(Lr, cv2.COLOR_BGR2RGB)
        result = pose.process(image_rgb)
        pose_landmarks = result.pose_landmarks

        if pose_landmarks:
            hL, wL = Lr.shape[:2]
            coords = {}
            for name, idx in important_landmarks.items():
                lm = pose_landmarks.landmark[idx]
                coords[name] = (lm.x * wL, lm.y * hL)

            left_xoff = xoff_for("L", W, SWAP_DISPLAY)
            for name, (x, y) in coords.items():
                joint_color = (0, 0, 255) if name in hand_parts else (0, 255, 0)
                cv2.circle(vis, (int(x)+left_xoff, int(y)), 6, joint_color, -1)
                cv2.putText(vis, f"{name}:({int(x)},{int(y)})",
                            (int(x)+left_xoff+6, int(y)-6),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0,0,0), 1, cv2.LINE_AA)

            # (NEW) í˜„ìž¬ íƒ€ê¹ƒ í™€ë“œì— ëŒ€í•œ 'ì†ê°€ë½ in polygon' ì¹´ìš´íŠ¸ â†’ ìžë™ ì§„í–‰
            if auto_advance_enabled and (current_target_id in idxL):
                hold = idxL[current_target_id]
                for name, (x, y) in coords.items():
                    inside = cv2.pointPolygonTest(hold["contour"], (x, y), False) >= 0
                    key = (name, current_target_id)
                    if inside:
                        touch_counters[key] = touch_counters.get(key, 0) + 1
                        if touch_counters[key] >= TOUCH_THRESHOLD:
                            now = time.time()
                            if now - last_advanced_time > ADV_COOLDOWN:
                                # ê·¸ë¦½ ê¸°ë¡ ì €ìž¥ (1íšŒ)
                                if not already_grabbed.get(key):
                                    cx, cy = hold["center"]
                                    grip_records.append([name, current_target_id, cx, cy])
                                    already_grabbed[key] = True

                                # ë‹¤ìŒ íƒ€ê¹ƒìœ¼ë¡œ ì´ë™
                                cur_idx = sorted_ids.index(current_target_id) if current_target_id in sorted_ids else -1
                                if (cur_idx >= 0) and (cur_idx + 1 < len(sorted_ids)):
                                    next_id = sorted_ids[cur_idx + 1]
                                    current_target_id = next_id
                                    nxt = by_id[next_id]
                                    yaw_cmd, pitch_cmd = apply_calibration(nxt["yaw_deg"], nxt["pitch_deg"])
                                    send_servo_angles(ctl, yaw_cmd, pitch_cmd)
                                    print(f"[Auto-Advance] â†’ ID{next_id}")
                                    last_advanced_time = now
                                else:
                                    print("[Auto-Advance] ë” ì´ìƒ ë‹¤ìŒ í™€ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        touch_counters[key] = 0

        # FPS
        t_now = time.time(); fps = 1.0 / max(t_now - (t_prev), 1e-6); t_prev = t_now
        cv2.putText(vis, f"FPS: {fps:.1f} (YOLO merged 10f; MP Left; Auto-Advance={'ON' if auto_advance_enabled else 'OFF'})",
                    (10, H-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)
        cv2.putText(vis, f"FPS: {fps:.1f} (YOLO merged 10f; MP Left; Auto-Advance={'ON' if auto_advance_enabled else 'OFF'})",
                    (10, H-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 1, cv2.LINE_AA)

        imshow_scaled(WINDOW_NAME, vis, PREVIEW_MAX_W)
        if SAVE_VIDEO: out.write(vis)

        frame_idx += 1
        k = cv2.waitKey(1) & 0xFF
        if k == ord('q'):
            break
        # ìˆ˜ë™ ìŠ¤í‚µ: 'n' â†’ ë‹¤ìŒ í™€ë“œë¡œ ê°•ì œ ì´ë™
        elif k == ord('n') and sorted_ids:
            if current_target_id in sorted_ids:
                i = sorted_ids.index(current_target_id)
                if i + 1 < len(sorted_ids):
                    current_target_id = sorted_ids[i+1]
                    nxt = by_id[current_target_id]
                    yaw_cmd, pitch_cmd = apply_calibration(nxt["yaw_deg"], nxt["pitch_deg"])
                    send_servo_angles(ctl, yaw_cmd, pitch_cmd)
                    print(f"[Manual Next] â†’ ID{current_target_id}")

    # ì •ë¦¬
    cap1.release(); cap2.release()
    if SAVE_VIDEO:
        out.release(); print(f"[Info] ì €ìž¥ ì™„ë£Œ: {OUT_PATH}")
    cv2.destroyAllWindows()
    try:
        ctl.close()
    except:
        pass

    # ê·¸ë¦½ ê¸°ë¡ ì €ìž¥
    with open(CSV_GRIPS_PATH, "w", newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(["part", "hold_id", "cx", "cy"])
        writer.writerows(grip_records)
    print(f"[Info] ê·¸ë¦½ CSV: {CSV_GRIPS_PATH} (í–‰ ìˆ˜: {len(grip_records)})")

if __name__ == "__main__":
    main()
